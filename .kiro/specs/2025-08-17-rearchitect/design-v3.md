# Hail-Mary ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæ›¸ v3.0

## ğŸ“‹ æ–‡æ›¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

- **ä½œæˆæ—¥**: 2025-08-17
- **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 3.0.0
- **ä½œæˆè€…**: Architecture Team
- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Final Draft
- **å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‹ã‚‰ã®å¤‰æ›´**: 
  - FTS5ãƒ­ã‚¸ãƒƒã‚¯ä¿è­·æˆ¦ç•¥ã®å°å…¥
  - Operationså±¤ã®ç´°åˆ†åŒ–
  - é«˜æ€§èƒ½DIæˆ¦ç•¥
  - è©³ç´°ã‚¨ãƒ©ãƒ¼éšå±¤ã®å°å…¥

## ğŸ¯ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

### v3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é©æ–°

v2.0ã®4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ç‰¹å®šã•ã‚ŒãŸé‡è¦ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹æœ€çµ‚è¨­è¨ˆã§ã™ã€‚å®Ÿè£…ã®ç¾å®Ÿæ€§ã¨ç†è«–çš„ãªæœ€é©æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’é‡è¦–ã—ã€æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã®æ—¢å­˜æ©Ÿèƒ½ã‚’å®Œå…¨ã«ä¿è­·ã—ãªãŒã‚‰ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ç°¡ç´ åŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

**ä¸»è¦ãªæ”¹å–„ç‚¹**:
1. **FTS5ãƒ­ã‚¸ãƒƒã‚¯ã®å°‚ç”¨å±¤ã¸ã®åˆ†é›¢**: è¤‡é›‘ãªæ—¥æœ¬èªå‡¦ç†ã‚’`FtsQueryBuilder`ã«éš”é›¢
2. **Operationså±¤ã®ç´°åˆ†åŒ–**: å˜ä¸€è²¬ä»»åŸå‰‡ã«åŸºã¥ã3ã¤ã®å°‚é–€Operations
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–DI**: å…·è±¡å‹ã¨trait objectsã®æˆ¦ç•¥çš„ä½¿ã„åˆ†ã‘
4. **éšå±¤çš„ã‚¨ãƒ©ãƒ¼ã‚·ã‚¹ãƒ†ãƒ **: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»æ“ä½œãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã®æ˜ç¢ºãªåˆ†é›¢
5. **Command/Queryãƒ‘ã‚¿ãƒ¼ãƒ³**: CQRS-liteã«ã‚ˆã‚‹èª­ã¿æ›¸ãåˆ†é›¢

### æœŸå¾…ã•ã‚Œã‚‹æˆæœ

- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: Arc<dyn>å‰Šæ¸›ã«ã‚ˆã‚Š20-30%ã®å¿œç­”æ™‚é–“æ”¹å–„
- **ä¿å®ˆæ€§**: 200è¡Œä»¥ä¸‹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã§èªçŸ¥è² è·50%å‰Šæ¸›
- **æ¤œç´¢å“è³ª**: FTS5ãƒ­ã‚¸ãƒƒã‚¯å®Œå…¨ä¿è­·ã«ã‚ˆã‚Šæ—¥æœ¬èªæ¤œç´¢ç²¾åº¦100%ç¶­æŒ
- **é–‹ç™ºé€Ÿåº¦**: æ˜ç¢ºãªè²¬ä»»åˆ†é›¢ã«ã‚ˆã‚Šæ–°æ©Ÿèƒ½é–‹ç™ºæ™‚é–“35%çŸ­ç¸®
- **ãƒ†ã‚¹ãƒˆåŠ¹ç‡**: å˜ä½“ãƒ†ã‚¹ãƒˆå¯èƒ½æ€§å‘ä¸Šã«ã‚ˆã‚Šãƒã‚°ç™ºè¦‹ç‡40%å‘ä¸Š

## ğŸ—ï¸ v3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°

### 4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆè²¬ä»»åˆ†é›¢å¼·åŒ–ç‰ˆï¼‰

```mermaid
%%{init: {
  'theme': 'dark',
  'themeCSS': '
    .nodeLabel { color: #FD971F !important; }
    .edgeLabel { color: #A6E22E !important; background-color: transparent !important; }
    .cluster rect { fill: #272822 !important; stroke: #F92672 !important; stroke-width: 2px !important; rx: 5px !important; ry: 5px !important; }
    .node rect, .node circle, .node ellipse, .node polygon, .node path { fill: #272822 !important; stroke: #A6E22E !important; stroke-width: 2px !important; }
    .flowchart-link { stroke: #66D9EF !important; stroke-width: 2px !important; }
  '
}}%%
graph TB
    subgraph "External Systems"
        CLI[CLI Interface]
        DB[(SQLite + FTS5)]
        MCP[MCP Server]
        EMB[Embedding Service]
    end
    
    subgraph "Application Architecture"
        direction TB
        
        subgraph "Presentation Layer"
            CMD[Commands/Handlers]
            VAL[Input Validation]
        end
        
        subgraph "Business Layer"
            subgraph "Domain"
                MODEL[Memory Model]
                VALUE[Value Objects]
                ERR[Error Hierarchy]
            end
            
            subgraph "Operations"
                CORE[Core Operations]
                SEARCH[Search Operations]
                ANALYTICS[Analytics Operations]
            end
        end
        
        subgraph "Database Layer"
            REPO[Repository Impl]
            FTS[FTS Query Builder]
            CACHE[Query Cache]
        end
        
        subgraph "Infrastructure Layer"
            MCPS[MCP Server]
            EMBS[Embedding Service]
            PERF[Performance Monitor]
        end
    end
    
    CLI --> CMD
    CMD --> VAL
    VAL --> CORE
    VAL --> SEARCH
    VAL --> ANALYTICS
    
    CORE --> MODEL
    SEARCH --> MODEL
    ANALYTICS --> MODEL
    
    CORE --> REPO
    SEARCH --> FTS
    SEARCH --> CACHE
    ANALYTICS --> REPO
    
    FTS --> REPO
    CACHE --> REPO
    REPO --> DB
    
    MCPS --> MCP
    EMBS --> EMB
    PERF --> CORE
    PERF --> SEARCH
    PERF --> ANALYTICS
    
    classDef presentation fill:#272822,stroke:#FD971F,stroke-width:2px
    classDef business fill:#272822,stroke:#F92672,stroke-width:3px
    classDef database fill:#272822,stroke:#A6E22E,stroke-width:2px
    classDef infrastructure fill:#272822,stroke:#AE81FF,stroke-width:2px
    classDef external fill:#272822,stroke:#66D9EF,stroke-width:2px,stroke-dasharray: 5 5
    classDef highlighted fill:#AE81FF,stroke:#66D9EF,stroke-width:3px,color:#FFF
    
    class CMD,VAL presentation
    class MODEL,VALUE,ERR,CORE,SEARCH,ANALYTICS business
    class REPO,FTS,CACHE database
    class MCPS,EMBS,PERF infrastructure
    class CLI,DB,MCP,EMB external
    class FTS highlighted
```

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ï¼ˆæœ€çµ‚ç‰ˆï¼‰

```
src/
â”œâ”€â”€ business/               # ãƒ“ã‚¸ãƒã‚¹å±¤
â”‚   â”œâ”€â”€ domain/             # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
â”‚   â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”‚   â”œâ”€â”€ model.rs        # Memory ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆç´”ç²‹ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰
â”‚   â”‚   â”‚   â”œâ”€â”€ value_objects.rs # MemoryId, MemoryTypeç­‰
â”‚   â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ errors.rs           # éšå±¤çš„ã‚¨ãƒ©ãƒ¼å®šç¾©
â”‚   â”‚
â”‚   â””â”€â”€ operations/         # ãƒ“ã‚¸ãƒã‚¹æ“ä½œï¼ˆåˆ†å‰²ç‰ˆï¼‰
â”‚       â”œâ”€â”€ core/
â”‚       â”‚   â”œâ”€â”€ memory_ops.rs   # åŸºæœ¬CRUDæ“ä½œï¼ˆ<150è¡Œï¼‰
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ search/
â”‚       â”‚   â”œâ”€â”€ text_search.rs  # ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ï¼ˆ<180è¡Œï¼‰
â”‚       â”‚   â”œâ”€â”€ semantic_search.rs # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ analytics/
â”‚       â”‚   â”œâ”€â”€ clustering.rs   # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆ<200è¡Œï¼‰
â”‚       â”‚   â”œâ”€â”€ deduplication.rs # é‡è¤‡æ’é™¤
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â””â”€â”€ mod.rs
â”‚
â”œâ”€â”€ database/               # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å±¤
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”œâ”€â”€ sqlite_memory.rs    # SqliteMemoryRepository
â”‚   â”‚   â”œâ”€â”€ traits.rs           # Repository traitå®šç¾©
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ query_builders/     # â­ FTS5ãƒ­ã‚¸ãƒƒã‚¯ä¿è­·
â”‚   â”‚   â”œâ”€â”€ fts_query_builder.rs # æ—¢å­˜FTS5ãƒ­ã‚¸ãƒƒã‚¯å®Œå…¨ä¿å­˜
â”‚   â”‚   â”œâ”€â”€ query_optimizer.rs   # ã‚¯ã‚¨ãƒªæœ€é©åŒ–
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”œâ”€â”€ query_cache.rs      # ã‚¯ã‚¨ãƒªçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â””â”€â”€ migrations/         # ã‚¹ã‚­ãƒ¼ãƒç®¡ç†
â”‚
â”œâ”€â”€ infrastructure/         # ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£å±¤
â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”œâ”€â”€ server.rs           # MCP ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…
â”‚   â”‚   â”œâ”€â”€ handlers.rs         # MCP ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ service.rs          # Embedding ã‚µãƒ¼ãƒ“ã‚¹ trait
â”‚   â”‚   â”œâ”€â”€ fastembed.rs        # FastEmbed å®Ÿè£…
â”‚   â”‚   â”œâ”€â”€ openai.rs           # OpenAI å®Ÿè£…
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ monitoring/         # â­ æ–°è¦ï¼šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
â”‚   â”‚   â”œâ”€â”€ metrics.rs          # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
â”‚   â”‚   â”œâ”€â”€ tracer.rs           # æ“ä½œãƒˆãƒ¬ãƒ¼ã‚¹
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â””â”€â”€ mod.rs
â”‚
â”œâ”€â”€ commands/               # ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å±¤
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ serve.rs            # MCP ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
â”‚   â”‚   â”œâ”€â”€ search.rs           # æ¤œç´¢ã‚³ãƒãƒ³ãƒ‰
â”‚   â”‚   â”œâ”€â”€ list.rs             # ãƒªã‚¹ãƒˆè¡¨ç¤º
â”‚   â”‚   â”œâ”€â”€ delete.rs           # å‰Šé™¤ã‚³ãƒãƒ³ãƒ‰
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ validation.rs       # â­ æ–°è¦ï¼šå…¥åŠ›æ¤œè¨¼
â”‚   â””â”€â”€ mod.rs
â”‚
â”œâ”€â”€ main.rs                 # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ lib.rs                  # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
â””â”€â”€ tests/                  # ãƒ†ã‚¹ãƒˆ
    â”œâ”€â”€ unit/
    â”‚   â”œâ”€â”€ domain/
    â”‚   â”œâ”€â”€ operations/
    â”‚   â””â”€â”€ database/
    â”œâ”€â”€ integration/
    â”‚   â””â”€â”€ end_to_end.rs
    â””â”€â”€ performance/        # â­ æ–°è¦ï¼šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        â””â”€â”€ benchmarks.rs
```

## ğŸ“ é‡è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è©³ç´°è¨­è¨ˆ

### 1. FTS5 Query Builderï¼ˆæ—¥æœ¬èªå‡¦ç†ã®å®Œå…¨ä¿è­·ï¼‰

```rust
// database/query_builders/fts_query_builder.rs
use crate::business::domain::errors::{QueryBuildError, ValidationError};
use std::collections::HashMap;

/// FTS5ã‚¯ã‚¨ãƒªãƒ“ãƒ«ãƒ€ãƒ¼ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯å®Œå…¨ä¿å­˜ï¼‰
pub struct FtsQueryBuilder {
    query: String,
    constraints: Vec<QueryConstraint>,
    options: QueryOptions,
}

impl FtsQueryBuilder {
    /// æ—¥æœ¬èªã¨è‹±èªã®å¢ƒç•Œã«ã‚¹ãƒšãƒ¼ã‚¹ã‚’æŒ¿å…¥ã™ã‚‹ï¼ˆå®Œå…¨ä¿å­˜ï¼‰
    /// å…ƒ: src/memory/service.rs:45-73
    pub fn normalize_content_for_fts(content: &str) -> String {
        let mut result = String::new();
        let mut prev_is_ascii = false;
        let mut prev_char: Option<char> = None;

        for ch in content.chars() {
            let curr_is_ascii = ch.is_ascii() && !ch.is_ascii_whitespace();
            let curr_is_japanese = matches!(
                ch, 
                '\u{3040}'..='\u{309F}' | // ã²ã‚‰ãŒãª
                '\u{30A0}'..='\u{30FF}' | // ã‚«ã‚¿ã‚«ãƒŠ
                '\u{4E00}'..='\u{9FAF}'   // æ¼¢å­—
            );

            // å¢ƒç•Œæ¤œå‡º: ASCIIâ†’æ—¥æœ¬èª ã¾ãŸã¯ æ—¥æœ¬èªâ†’ASCII
            if let Some(prev) = prev_char {
                let prev_is_japanese = matches!(
                    prev,
                    '\u{3040}'..='\u{309F}' | 
                    '\u{30A0}'..='\u{30FF}' | 
                    '\u{4E00}'..='\u{9FAF}'
                );

                // ASCIIï¼ˆãƒã‚¤ãƒ•ãƒ³å«ã‚€ï¼‰ã¨æ—¥æœ¬èªã®å¢ƒç•Œ
                if (prev_is_ascii && curr_is_japanese) || 
                   (prev_is_japanese && curr_is_ascii) {
                    // ã‚¹ãƒšãƒ¼ã‚¹ãŒã¾ã ãªã„å ´åˆã®ã¿æŒ¿å…¥
                    if !prev.is_ascii_whitespace() && !ch.is_ascii_whitespace() {
                        result.push(' ');
                    }
                }
            }

            result.push(ch);
            prev_is_ascii = curr_is_ascii;
            prev_char = Some(ch);
        }

        result
    }

    /// FTS5ã‚¯ã‚¨ãƒªã‚’éƒ¨åˆ†ãƒãƒƒãƒå¯¾å¿œã«å¼·åŒ–ã™ã‚‹ï¼ˆå®Œå…¨ä¿å­˜ï¼‰
    /// å…ƒ: src/memory/service.rs:75-166
    pub fn enhance_query_for_partial_match(query: &str) -> Result<String, QueryBuildError> {
        // æ—¢ã«ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if query.contains('*') {
            return Ok(query.to_string());
        }

        // FTS5ã®ãƒ–ãƒ¼ãƒªã‚¢ãƒ³æ¼”ç®—å­ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆAND, OR, NOTï¼‰
        if query.contains(" AND ") || query.contains(" OR ") || query.contains(" NOT ") {
            return Ok(query.to_string());
        }

        // ç‰¹æ®Šæ–‡å­—ãŒå¤šæ•°å«ã¾ã‚Œã‚‹å ´åˆã®å‡¦ç†
        let problematic_chars = ['@', '#', '$', '%', '&', '^', '~', '`', '|', '\\'];
        if query.chars().any(|c| problematic_chars.contains(&c)) {
            let escaped = query.replace('"', "\"\"");
            return Ok(format!("\"{}\"", escaped));
        }

        // ãƒã‚¤ãƒ•ãƒ³ã‚’å«ã‚€å ´åˆã®ç‰¹åˆ¥å‡¦ç†
        let has_hyphen = query.contains('-');
        let has_non_ascii = !query.is_ascii();

        // æ—¥æœ¬èªã¨ãƒã‚¤ãƒ•ãƒ³ãŒæ··åœ¨ã™ã‚‹å ´åˆ
        if has_non_ascii && has_hyphen {
            let escaped = query.replace('"', "\"\"");
            return Ok(format!("\"{}\"*", escaped));
        }

        if has_hyphen {
            let escaped = query.replace('"', "\"\"");
            return Ok(format!("\"{}\"", escaped));
        }

        // :: ã‚’å«ã‚€å ´åˆï¼ˆåå‰ç©ºé–“ã‚„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å‚ç…§ï¼‰ã®å‡¦ç†
        if query.contains("::") {
            let processed = query.replace("::", "_COLON_COLON_");
            let words: Vec<String> = processed
                .split_whitespace()
                .map(|word| {
                    let restored = word.replace("_COLON_COLON_", "::");
                    format!("\"{}\"", restored)
                })
                .collect();
            return Ok(words.join(" "));
        }

        // ç‰¹æ®Šæ–‡å­—ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
        let needs_escaping = query.contains('\'') || query.contains('"') || query.contains(';');
        if needs_escaping {
            let escaped = query.replace('"', "\"\"");
            return Ok(format!("\"{}\"", escaped));
        }

        // æ—¥æœ¬èªãŒå«ã¾ã‚Œã‚‹å ´åˆ
        if has_non_ascii {
            return Ok(query
                .split_whitespace()
                .map(|word| format!("\"{}\"", word))
                .collect::<Vec<_>>()
                .join(" "));
        }

        // å„å˜èªã«ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹æ¤œç´¢ï¼‰
        Ok(query
            .split_whitespace()
            .map(|word| {
                let safe_word = word
                    .replace('(', "\\(")
                    .replace(')', "\\)")
                    .replace('[', "\\[")
                    .replace(']', "\\]");
                format!("{}*", safe_word)
            })
            .collect::<Vec<_>>()
            .join(" "))
    }

    /// ã‚¯ã‚¨ãƒªãƒ“ãƒ«ãƒ€ãƒ¼ã®ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰
    pub fn new(query: String) -> Self {
        Self {
            query,
            constraints: Vec::new(),
            options: QueryOptions::default(),
        }
    }

    pub fn with_memory_type(mut self, memory_type: &str) -> Self {
        self.constraints.push(QueryConstraint::MemoryType(memory_type.to_string()));
        self
    }

    pub fn with_tags(mut self, tags: Vec<String>) -> Self {
        self.constraints.push(QueryConstraint::Tags(tags));
        self
    }

    pub fn with_limit(mut self, limit: usize) -> Self {
        self.options.limit = Some(limit);
        self
    }

    /// æœ€é©åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
    pub fn build(self) -> Result<OptimizedQuery, QueryBuildError> {
        // ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ­£è¦åŒ–
        let normalized_query = if self.options.normalize_japanese {
            Self::normalize_content_for_fts(&self.query)
        } else {
            self.query.clone()
        };

        // éƒ¨åˆ†ãƒãƒƒãƒå¼·åŒ–
        let enhanced_query = Self::enhance_query_for_partial_match(&normalized_query)?;

        // ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦ã®æ¨å®š
        let complexity = self.estimate_complexity(&enhanced_query);

        Ok(OptimizedQuery {
            sql: self.build_sql(&enhanced_query)?,
            parameters: self.build_parameters(),
            complexity,
            cache_key: self.generate_cache_key(&enhanced_query),
        })
    }

    fn estimate_complexity(&self, query: &str) -> QueryComplexity {
        let token_count = query.split_whitespace().count();
        let has_wildcards = query.contains('*');
        let constraint_count = self.constraints.len();

        if token_count > 5 || constraint_count > 2 {
            QueryComplexity::High
        } else if has_wildcards || constraint_count > 0 {
            QueryComplexity::Medium
        } else {
            QueryComplexity::Low
        }
    }

    fn build_sql(&self, enhanced_query: &str) -> Result<String, QueryBuildError> {
        let mut sql = format!(
            "SELECT * FROM memories_fts WHERE memories_fts MATCH ?"
        );

        for constraint in &self.constraints {
            match constraint {
                QueryConstraint::MemoryType(mt) => {
                    sql.push_str(&format!(" AND memory_type = '{}'", mt));
                }
                QueryConstraint::Tags(tags) => {
                    let tag_conditions = tags.iter()
                        .map(|t| format!("tags LIKE '%{}%'", t))
                        .collect::<Vec<_>>()
                        .join(" AND ");
                    sql.push_str(&format!(" AND ({})", tag_conditions));
                }
            }
        }

        if let Some(limit) = self.options.limit {
            sql.push_str(&format!(" LIMIT {}", limit));
        }

        Ok(sql)
    }

    fn build_parameters(&self) -> HashMap<String, String> {
        let mut params = HashMap::new();
        params.insert("query".to_string(), self.query.clone());
        params
    }

    fn generate_cache_key(&self, query: &str) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        query.hash(&mut hasher);
        self.constraints.hash(&mut hasher);
        self.options.hash(&mut hasher);
        
        format!("fts_query_{:x}", hasher.finish())
    }
}

#[derive(Debug, Clone)]
pub enum QueryConstraint {
    MemoryType(String),
    Tags(Vec<String>),
}

#[derive(Debug, Clone, Default, Hash)]
pub struct QueryOptions {
    pub limit: Option<usize>,
    pub normalize_japanese: bool,
}

#[derive(Debug)]
pub struct OptimizedQuery {
    pub sql: String,
    pub parameters: HashMap<String, String>,
    pub complexity: QueryComplexity,
    pub cache_key: String,
}

#[derive(Debug, Clone, Copy)]
pub enum QueryComplexity {
    Low,    // < 100ms expected
    Medium, // 100-500ms expected
    High,   // > 500ms expected
}
```

### 2. åˆ†å‰²ã•ã‚ŒãŸOperationså±¤

#### Core Memory Operationsï¼ˆåŸºæœ¬CRUDï¼‰

```rust
// business/operations/core/memory_ops.rs
use crate::business::domain::memory::{Memory, MemoryId, MemoryType};
use crate::business::domain::errors::OperationError;
use crate::database::repositories::traits::MemoryRepository;

/// åŸºæœ¬çš„ãªãƒ¡ãƒ¢ãƒªæ“ä½œï¼ˆ150è¡Œä»¥ä¸‹ï¼‰
pub struct CoreMemoryOperations<R: MemoryRepository> {
    repository: R,
}

impl<R: MemoryRepository> CoreMemoryOperations<R> {
    pub fn new(repository: R) -> Self {
        Self { repository }
    }

    /// ãƒ¡ãƒ¢ãƒªã‚’ä½œæˆã¾ãŸã¯æ›´æ–°
    pub async fn upsert_memory(
        &self,
        memory_type: MemoryType,
        title: String,
        content: String,
        tags: Option<Vec<String>>,
    ) -> Result<Memory, OperationError> {
        // æ—¢å­˜ãƒã‚§ãƒƒã‚¯
        if let Some(mut existing) = self.repository
            .find_by_title(&title, &memory_type)
            .await
            .map_err(|e| OperationError::repository_error(e))? 
        {
            // æ›´æ–°å‡¦ç†
            existing.update_content(content)
                .map_err(|e| OperationError::validation_error(e))?;
            
            if let Some(tags) = tags {
                for tag in tags {
                    existing.add_tag(tag)
                        .map_err(|e| OperationError::validation_error(e))?;
                }
            }
            
            self.repository.update(&existing).await
                .map_err(|e| OperationError::repository_error(e))?;
            
            return Ok(existing);
        }

        // æ–°è¦ä½œæˆ
        let mut memory = Memory::new(memory_type, title, content)
            .map_err(|e| OperationError::validation_error(e))?;
        
        if let Some(tags) = tags {
            for tag in tags {
                memory.add_tag(tag)
                    .map_err(|e| OperationError::validation_error(e))?;
            }
        }
        
        self.repository.save(&memory).await
            .map_err(|e| OperationError::repository_error(e))?;
        
        Ok(memory)
    }

    /// IDã§ãƒ¡ãƒ¢ãƒªã‚’å–å¾—
    pub async fn get_memory(&self, id: &MemoryId) -> Result<Option<Memory>, OperationError> {
        self.repository.find_by_id(id).await
            .map_err(|e| OperationError::repository_error(e))
    }

    /// ãƒ¡ãƒ¢ãƒªã‚’å‰Šé™¤ï¼ˆè«–ç†å‰Šé™¤ï¼‰
    pub async fn delete_memory(&self, id: &MemoryId) -> Result<bool, OperationError> {
        if let Some(mut memory) = self.get_memory(id).await? {
            memory.soft_delete();
            self.repository.update(&memory).await
                .map_err(|e| OperationError::repository_error(e))?;
            Ok(true)
        } else {
            Ok(false)
        }
    }

    /// ãƒ¡ãƒ¢ãƒªã‚’ãƒªã‚¹ãƒˆ
    pub async fn list_memories(
        &self,
        memory_type: Option<MemoryType>,
        limit: usize,
    ) -> Result<Vec<Memory>, OperationError> {
        if let Some(mt) = memory_type {
            self.repository.list_by_type(&mt, limit).await
        } else {
            self.repository.list_recent(limit).await
        }
        .map_err(|e| OperationError::repository_error(e))
    }
}
```

#### Search Operationsï¼ˆæ¤œç´¢ç‰¹åŒ–ï¼‰

```rust
// business/operations/search/text_search.rs
use crate::business::domain::memory::{Memory, MemoryType};
use crate::business::domain::errors::SearchError;
use crate::database::query_builders::FtsQueryBuilder;
use crate::database::repositories::traits::MemoryRepository;
use crate::database::cache::QueryCache;

/// ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢æ“ä½œï¼ˆ180è¡Œä»¥ä¸‹ï¼‰
pub struct TextSearchOperations<R: MemoryRepository> {
    repository: R,
    cache: Option<QueryCache>,
}

impl<R: MemoryRepository> TextSearchOperations<R> {
    pub fn new(repository: R, cache: Option<QueryCache>) -> Self {
        Self { repository, cache }
    }

    /// é«˜åº¦ãªæ¤œç´¢ï¼ˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä»˜ãï¼‰
    pub async fn search_with_scoring(
        &self,
        query: String,
        memory_type: Option<MemoryType>,
        tags: Option<Vec<String>>,
        limit: usize,
    ) -> Result<Vec<(Memory, f32)>, SearchError> {
        // ã‚¯ã‚¨ãƒªãƒ“ãƒ«ãƒ€ãƒ¼ã§æœ€é©åŒ–
        let mut builder = FtsQueryBuilder::new(query.clone())
            .with_limit(limit * 2); // ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚§ãƒƒãƒã—ã¦å¾Œã§ãƒ•ã‚£ãƒ«ã‚¿

        if let Some(mt) = memory_type {
            builder = builder.with_memory_type(&mt.to_string());
        }

        if let Some(tags) = tags.clone() {
            builder = builder.with_tags(tags);
        }

        let optimized = builder.build()
            .map_err(|e| SearchError::query_build_error(e))?;

        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if let Some(cache) = &self.cache {
            if let Some(cached) = cache.get(&optimized.cache_key).await {
                return Ok(cached);
            }
        }

        // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢
        let candidates = self.repository
            .search_fts(&optimized)
            .await
            .map_err(|e| SearchError::repository_error(e))?;

        // ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        let mut scored: Vec<(Memory, f32)> = candidates
            .into_iter()
            .map(|memory| {
                let score = if query.is_empty() {
                    memory.confidence() * (1.0 + (memory.reference_count() as f32).log10())
                } else {
                    memory.calculate_relevance_score(&query)
                };
                (memory, score)
            })
            .filter(|(_, score)| *score > 0.0)
            .collect();

        // ã‚½ãƒ¼ãƒˆã¨åˆ‡ã‚Šè©°ã‚
        scored.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        scored.truncate(limit);

        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        if let Some(cache) = &self.cache {
            cache.set(optimized.cache_key, scored.clone()).await;
        }

        Ok(scored)
    }

    /// ã‚·ãƒ³ãƒ—ãƒ«ãªæ¤œç´¢
    pub async fn search(
        &self,
        query: String,
        limit: usize,
    ) -> Result<Vec<Memory>, SearchError> {
        let scored = self.search_with_scoring(query, None, None, limit).await?;
        Ok(scored.into_iter().map(|(memory, _)| memory).collect())
    }

    /// ã‚¿ã‚°ãƒ™ãƒ¼ã‚¹æ¤œç´¢
    pub async fn search_by_tags(
        &self,
        tags: Vec<String>,
        limit: usize,
    ) -> Result<Vec<Memory>, SearchError> {
        self.repository
            .find_by_tags(&tags, limit)
            .await
            .map_err(|e| SearchError::repository_error(e))
    }
}
```

#### Analytics Operationsï¼ˆåˆ†æãƒ»æœ€é©åŒ–ï¼‰

```rust
// business/operations/analytics/clustering.rs
use crate::business::domain::memory::Memory;
use crate::business::domain::errors::AnalyticsError;
use crate::database::repositories::traits::MemoryRepository;

/// ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨åˆ†ææ“ä½œï¼ˆ200è¡Œä»¥ä¸‹ï¼‰
pub struct ClusteringOperations<R: MemoryRepository> {
    repository: R,
}

impl<R: MemoryRepository> ClusteringOperations<R> {
    pub fn new(repository: R) -> Self {
        Self { repository }
    }

    /// é‡è¤‡ãƒ¡ãƒ¢ãƒªã‚’ãƒãƒ¼ã‚¸
    pub async fn merge_duplicates(&self) -> Result<MergeReport, AnalyticsError> {
        let all_memories = self.repository.list_all().await
            .map_err(|e| AnalyticsError::repository_error(e))?;
        
        let mut merged_count = 0;
        let mut processed_ids = std::collections::HashSet::new();

        for i in 0..all_memories.len() {
            if processed_ids.contains(all_memories[i].id()) {
                continue;
            }

            for j in i + 1..all_memories.len() {
                if processed_ids.contains(all_memories[j].id()) {
                    continue;
                }

                // ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«ã§ãƒãƒ¼ã‚¸å¯èƒ½ã‹åˆ¤å®š
                if all_memories[i].can_merge_with(&all_memories[j]) {
                    let mut base = all_memories[i].clone();
                    let to_merge = &all_memories[j];

                    // ã‚ˆã‚Šæ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ¡ç”¨
                    if to_merge.last_accessed() > base.last_accessed() {
                        base.update_content(to_merge.content().to_string())
                            .map_err(|e| AnalyticsError::validation_error(e))?;
                    }

                    // ã‚¿ã‚°ã‚’ãƒãƒ¼ã‚¸
                    for tag in to_merge.tags() {
                        let _ = base.add_tag(tag.clone());
                    }

                    // æ›´æ–°ã¨å‰Šé™¤
                    self.repository.update(&base).await
                        .map_err(|e| AnalyticsError::repository_error(e))?;
                    self.repository.soft_delete(to_merge.id()).await
                        .map_err(|e| AnalyticsError::repository_error(e))?;

                    processed_ids.insert(to_merge.id().clone());
                    merged_count += 1;
                }
            }

            processed_ids.insert(all_memories[i].id().clone());
        }

        Ok(MergeReport {
            total_memories: all_memories.len(),
            merged_count,
            remaining_memories: all_memories.len() - merged_count,
        })
    }

    /// ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãŒå¿…è¦ãªãƒ¡ãƒ¢ãƒªã‚’å‡¦ç†
    pub async fn archive_old_memories(&self) -> Result<ArchiveReport, AnalyticsError> {
        let all_memories = self.repository.list_all().await
            .map_err(|e| AnalyticsError::repository_error(e))?;
        
        let mut archived_count = 0;

        for memory in all_memories {
            if memory.needs_archiving() {
                // ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‡¦ç†
                self.repository.archive(memory.id()).await
                    .map_err(|e| AnalyticsError::repository_error(e))?;
                archived_count += 1;
            }
        }

        Ok(ArchiveReport { archived_count })
    }

    /// ãƒ¡ãƒ¢ãƒªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    pub async fn cluster_memories(
        &self,
        min_similarity: f32,
    ) -> Result<Vec<MemoryCluster>, AnalyticsError> {
        // ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿè£…çœç•¥ï¼‰
        Ok(Vec::new())
    }
}

pub struct MergeReport {
    pub total_memories: usize,
    pub merged_count: usize,
    pub remaining_memories: usize,
}

pub struct ArchiveReport {
    pub archived_count: usize,
}

pub struct MemoryCluster {
    pub id: String,
    pub members: Vec<Memory>,
    pub centroid: Memory,
    pub similarity_score: f32,
}
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–ã®ä¾å­˜æ€§æ³¨å…¥

```rust
// business/operations/mod.rs

/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ç‰ˆï¼ˆå…·è±¡å‹ä½¿ç”¨ï¼‰
pub struct OptimizedOperations {
    pub core: CoreMemoryOperations<SqliteMemoryRepository>,
    pub search: TextSearchOperations<SqliteMemoryRepository>,
    pub analytics: ClusteringOperations<SqliteMemoryRepository>,
}

impl OptimizedOperations {
    pub fn new(db_path: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let repository = SqliteMemoryRepository::new(db_path)?;
        let cache = QueryCache::new(1000); // 1000ã‚¨ãƒ³ãƒˆãƒªã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

        Ok(Self {
            core: CoreMemoryOperations::new(repository.clone()),
            search: TextSearchOperations::new(repository.clone(), Some(cache)),
            analytics: ClusteringOperations::new(repository),
        })
    }
}

/// æŸ”è»Ÿæ€§é‡è¦–ç‰ˆï¼ˆtrait objectsä½¿ç”¨ï¼‰
pub struct FlexibleOperations {
    pub core: CoreMemoryOperations<Box<dyn MemoryRepository>>,
    pub search: TextSearchOperations<Box<dyn MemoryRepository>>,
    pub analytics: ClusteringOperations<Box<dyn MemoryRepository>>,
}

impl FlexibleOperations {
    pub fn new(repository: Box<dyn MemoryRepository>) -> Self {
        Self {
            core: CoreMemoryOperations::new(repository.clone()),
            search: TextSearchOperations::new(repository.clone(), None),
            analytics: ClusteringOperations::new(repository),
        }
    }
}

/// å®Ÿè¡Œæ™‚ã«é¸æŠå¯èƒ½
pub enum OperationsMode {
    /// æœ¬ç•ªç’°å¢ƒç”¨ï¼ˆæœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼‰
    Production(OptimizedOperations),
    
    /// ãƒ†ã‚¹ãƒˆç’°å¢ƒç”¨ï¼ˆãƒ¢ãƒƒã‚¯å¯èƒ½ï¼‰
    Testing(FlexibleOperations),
    
    /// é–‹ç™ºç’°å¢ƒç”¨ï¼ˆãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ä»˜ãï¼‰
    Development {
        operations: FlexibleOperations,
        monitoring: PerformanceMonitor,
    },
}

impl OperationsMode {
    pub fn for_environment() -> Self {
        match std::env::var("APP_ENV").as_deref() {
            Ok("production") => {
                let ops = OptimizedOperations::new("/var/lib/hail-mary/memory.db")
                    .expect("Failed to initialize production operations");
                Self::Production(ops)
            }
            Ok("test") => {
                let repo = Box::new(MockMemoryRepository::new());
                Self::Testing(FlexibleOperations::new(repo))
            }
            _ => {
                let repo = Box::new(SqliteMemoryRepository::new("./dev.db").unwrap());
                let monitor = PerformanceMonitor::new();
                Self::Development {
                    operations: FlexibleOperations::new(repo),
                    monitoring: monitor,
                }
            }
        }
    }
}
```

### 4. éšå±¤çš„ã‚¨ãƒ©ãƒ¼ã‚·ã‚¹ãƒ†ãƒ 

```rust
// business/domain/errors.rs
use thiserror::Error;

/// ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«é•åï¼‰
#[derive(Error, Debug)]
pub enum DomainError {
    #[error("Invalid memory ID: {0}")]
    InvalidMemoryId(String),
    
    #[error("Title cannot be empty")]
    EmptyTitle,
    
    #[error("Content cannot be empty")]
    EmptyContent,
    
    #[error("Title too long: {length} characters (max: {max})")]
    TitleTooLong { length: usize, max: usize },
    
    #[error("Too many tags: {count} (max: {max})")]
    TooManyTags { count: usize, max: usize },
    
    #[error("Invalid tag: {0}")]
    InvalidTag(String),
    
    #[error("Memory type not supported: {0}")]
    UnsupportedMemoryType(String),
}

/// æ“ä½œã‚¨ãƒ©ãƒ¼ï¼ˆãƒ“ã‚¸ãƒã‚¹æ“ä½œã®å¤±æ•—ï¼‰
#[derive(Error, Debug)]
pub enum OperationError {
    #[error("Memory not found: {id}")]
    MemoryNotFound { id: String },
    
    #[error("Duplicate memory exists: {title}")]
    DuplicateMemory { title: String },
    
    #[error("Merge conflict between memories: {id1} and {id2}")]
    MergeConflict { id1: String, id2: String },
    
    #[error("Bulk operation partially failed: {succeeded} succeeded, {failed} failed")]
    BulkOperationPartialFailure {
        succeeded: usize,
        failed: usize,
        failures: Vec<String>,
    },
    
    #[error("Operation timeout: {operation} took longer than {timeout_ms}ms")]
    OperationTimeout { operation: String, timeout_ms: u64 },
    
    #[error("Validation error: {0}")]
    Validation(#[from] DomainError),
    
    #[error("Repository error: {0}")]
    Repository(Box<dyn std::error::Error + Send + Sync>),
}

impl OperationError {
    pub fn repository_error<E: std::error::Error + Send + Sync + 'static>(e: E) -> Self {
        Self::Repository(Box::new(e))
    }
    
    pub fn validation_error(e: DomainError) -> Self {
        Self::Validation(e)
    }
}

/// æ¤œç´¢ã‚¨ãƒ©ãƒ¼
#[derive(Error, Debug)]
pub enum SearchError {
    #[error("Invalid search query: {reason}")]
    InvalidQuery { reason: String },
    
    #[error("Query too complex: estimated cost {cost} exceeds limit {limit}")]
    QueryTooComplex { cost: u64, limit: u64 },
    
    #[error("No results found for query: {query}")]
    NoResults { query: String },
    
    #[error("Search timeout: query took longer than {timeout_ms}ms")]
    SearchTimeout { timeout_ms: u64 },
    
    #[error("Query build error: {0}")]
    QueryBuild(#[from] QueryBuildError),
    
    #[error("Repository error: {0}")]
    Repository(Box<dyn std::error::Error + Send + Sync>),
}

impl SearchError {
    pub fn repository_error<E: std::error::Error + Send + Sync + 'static>(e: E) -> Self {
        Self::Repository(Box::new(e))
    }
    
    pub fn query_build_error(e: QueryBuildError) -> Self {
        Self::QueryBuild(e)
    }
}

/// ã‚¯ã‚¨ãƒªãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼
#[derive(Error, Debug)]
pub enum QueryBuildError {
    #[error("Invalid FTS5 syntax: {0}")]
    InvalidFtsSyntax(String),
    
    #[error("Unsupported query pattern: {0}")]
    UnsupportedPattern(String),
    
    #[error("Query normalization failed: {0}")]
    NormalizationFailed(String),
}

/// åˆ†æã‚¨ãƒ©ãƒ¼
#[derive(Error, Debug)]
pub enum AnalyticsError {
    #[error("Insufficient data for analysis: need {required}, have {available}")]
    InsufficientData { required: usize, available: usize },
    
    #[error("Clustering failed: {reason}")]
    ClusteringFailed { reason: String },
    
    #[error("Archive operation failed: {reason}")]
    ArchiveFailed { reason: String },
    
    #[error("Validation error: {0}")]
    Validation(#[from] DomainError),
    
    #[error("Repository error: {0}")]
    Repository(Box<dyn std::error::Error + Send + Sync>),
}

impl AnalyticsError {
    pub fn repository_error<E: std::error::Error + Send + Sync + 'static>(e: E) -> Self {
        Self::Repository(Box::new(e))
    }
    
    pub fn validation_error(e: DomainError) -> Self {
        Self::Validation(e)
    }
}

/// ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚¨ãƒ©ãƒ¼
#[derive(Error, Debug)]
pub enum InfrastructureError {
    #[error("Database connection failed: {0}")]
    DatabaseConnection(String),
    
    #[error("Embedding service unavailable: {0}")]
    EmbeddingServiceUnavailable(String),
    
    #[error("MCP server error: {0}")]
    McpServerError(String),
    
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),
}

/// çµ±åˆã‚¨ãƒ©ãƒ¼å‹
#[derive(Error, Debug)]
pub enum HailMaryError {
    #[error("Domain error: {0}")]
    Domain(#[from] DomainError),
    
    #[error("Operation error: {0}")]
    Operation(#[from] OperationError),
    
    #[error("Search error: {0}")]
    Search(#[from] SearchError),
    
    #[error("Analytics error: {0}")]
    Analytics(#[from] AnalyticsError),
    
    #[error("Infrastructure error: {0}")]
    Infrastructure(#[from] InfrastructureError),
}

impl HailMaryError {
    /// ã‚¨ãƒ©ãƒ¼ãŒå›å¾©å¯èƒ½ã‹ã©ã†ã‹åˆ¤å®š
    pub fn is_recoverable(&self) -> bool {
        match self {
            Self::Domain(_) => false,        // ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«é•åã¯å›å¾©ä¸å¯
            Self::Operation(e) => {
                matches!(e, OperationError::OperationTimeout { .. })
            }
            Self::Search(e) => {
                matches!(e, SearchError::SearchTimeout { .. })
            }
            Self::Analytics(_) => false,
            Self::Infrastructure(_) => true, // ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ©ãƒ¼ã¯ãƒªãƒˆãƒ©ã‚¤å¯èƒ½
        }
    }
    
    /// æ¨å¥¨ã•ã‚Œã‚‹ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
    pub fn retry_strategy(&self) -> Option<RetryStrategy> {
        if self.is_recoverable() {
            Some(RetryStrategy::ExponentialBackoff {
                initial_delay_ms: 100,
                max_retries: 3,
                max_delay_ms: 5000,
            })
        } else {
            None
        }
    }
}

#[derive(Debug, Clone)]
pub enum RetryStrategy {
    ExponentialBackoff {
        initial_delay_ms: u64,
        max_retries: usize,
        max_delay_ms: u64,
    },
    FixedDelay {
        delay_ms: u64,
        max_retries: usize,
    },
}
```

### 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

```rust
// infrastructure/monitoring/metrics.rs
use std::time::{Duration, Instant};
use std::collections::HashMap;

/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
pub struct PerformanceMonitor {
    operation_times: HashMap<String, Vec<Duration>>,
    cache_hits: u64,
    cache_misses: u64,
    error_counts: HashMap<String, u64>,
}

impl PerformanceMonitor {
    pub fn new() -> Self {
        Self {
            operation_times: HashMap::new(),
            cache_hits: 0,
            cache_misses: 0,
            error_counts: HashMap::new(),
        }
    }

    /// æ“ä½œã®å®Ÿè¡Œæ™‚é–“ã‚’è¨˜éŒ²
    pub fn record_operation<F, T, E>(
        &mut self,
        operation_name: &str,
        f: F,
    ) -> Result<T, E>
    where
        F: FnOnce() -> Result<T, E>,
        E: std::fmt::Display,
    {
        let start = Instant::now();
        let result = f();
        let duration = start.elapsed();

        self.operation_times
            .entry(operation_name.to_string())
            .or_insert_with(Vec::new)
            .push(duration);

        if let Err(ref e) = result {
            *self.error_counts
                .entry(format!("{}:{}", operation_name, e))
                .or_insert(0) += 1;
        }

        result
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‚’è¨˜éŒ²
    pub fn record_cache_hit(&mut self) {
        self.cache_hits += 1;
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã‚’è¨˜éŒ²
    pub fn record_cache_miss(&mut self) {
        self.cache_misses += 1;
    }

    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    pub fn generate_report(&self) -> PerformanceReport {
        let mut operation_stats = HashMap::new();

        for (name, times) in &self.operation_times {
            if times.is_empty() {
                continue;
            }

            let mut sorted_times = times.clone();
            sorted_times.sort();

            let p50_idx = times.len() / 2;
            let p95_idx = (times.len() as f64 * 0.95) as usize;
            let p99_idx = (times.len() as f64 * 0.99) as usize;

            operation_stats.insert(
                name.clone(),
                OperationStats {
                    count: times.len(),
                    p50: sorted_times[p50_idx],
                    p95: sorted_times.get(p95_idx).copied().unwrap_or(sorted_times[p50_idx]),
                    p99: sorted_times.get(p99_idx).copied().unwrap_or(sorted_times[p95_idx]),
                    total: times.iter().sum(),
                },
            );
        }

        PerformanceReport {
            operation_stats,
            cache_hit_rate: if self.cache_hits + self.cache_misses > 0 {
                self.cache_hits as f64 / (self.cache_hits + self.cache_misses) as f64
            } else {
                0.0
            },
            error_counts: self.error_counts.clone(),
        }
    }
}

#[derive(Debug)]
pub struct PerformanceReport {
    pub operation_stats: HashMap<String, OperationStats>,
    pub cache_hit_rate: f64,
    pub error_counts: HashMap<String, u64>,
}

#[derive(Debug)]
pub struct OperationStats {
    pub count: usize,
    pub p50: Duration,
    pub p95: Duration,
    pub p99: Duration,
    pub total: Duration,
}
```

## ğŸ”„ ç§»è¡Œè¨ˆç”»ï¼ˆv3å°‚ç”¨ï¼‰

### Phase 1: FTS5ãƒ­ã‚¸ãƒƒã‚¯ä¿è­·ï¼ˆWeek 1ï¼‰â­ æœ€å„ªå…ˆ

**ã‚¿ã‚¹ã‚¯**:
1. `database/query_builders/fts_query_builder.rs` ä½œæˆ
2. æ—¢å­˜ã® `normalize_content_for_fts()` ã¨ `enhance_query_for_partial_match()` ã‚’å®Œå…¨ç§»æ¤
3. åŒ…æ‹¬çš„ãªæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆä½œæˆ
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿæ–½

**æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ**:
- [ ] æ—¢å­˜ã®æ¤œç´¢ã‚¯ã‚¨ãƒªãŒ100%äº’æ›æ€§ç¶­æŒ
- [ ] æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãŒæ­£ç¢º
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ãªã—ï¼ˆÂ±5%ä»¥å†…ï¼‰

### Phase 2: ã‚¨ãƒ©ãƒ¼éšå±¤æ§‹ç¯‰ï¼ˆWeek 2ï¼‰

**ã‚¿ã‚¹ã‚¯**:
1. `business/domain/errors.rs` ã«éšå±¤çš„ã‚¨ãƒ©ãƒ¼å®šç¾©
2. ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥ã¨ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
3. æ—¢å­˜ã‚¨ãƒ©ãƒ¼ã‹ã‚‰ã®ç§»è¡Œãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ

**æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ**:
- [ ] ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãŒã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹
- [ ] ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒä¿æŒã•ã‚Œã¦ã„ã‚‹
- [ ] å›å¾©å¯èƒ½æ€§ãŒæ­£ã—ãåˆ¤å®šã•ã‚Œã‚‹

### Phase 3: Operationså±¤åˆ†å‰²ï¼ˆWeek 3-4ï¼‰

**ã‚¿ã‚¹ã‚¯**:
1. `CoreMemoryOperations` å®Ÿè£…ï¼ˆåŸºæœ¬CRUDï¼‰
2. `TextSearchOperations` å®Ÿè£…ï¼ˆæ¤œç´¢ç‰¹åŒ–ï¼‰
3. `ClusteringOperations` å®Ÿè£…ï¼ˆåˆ†æç³»ï¼‰
4. æ—¢å­˜ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ã®æ®µéšçš„ç§»è¡Œ

**æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ**:
- [ ] å„Operations ãŒ200è¡Œä»¥ä¸‹
- [ ] å˜ä¸€è²¬ä»»åŸå‰‡ã®éµå®ˆ
- [ ] ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹äº’æ›æ€§ç¶­æŒ

### Phase 4: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–DIï¼ˆWeek 5ï¼‰

**ã‚¿ã‚¹ã‚¯**:
1. `OptimizedOperations` å®Ÿè£…ï¼ˆå…·è±¡å‹ä½¿ç”¨ï¼‰
2. `FlexibleOperations` å®Ÿè£…ï¼ˆtrait objectsï¼‰
3. ç’°å¢ƒåˆ¥ã®è‡ªå‹•é¸æŠãƒ­ã‚¸ãƒƒã‚¯
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

**æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ**:
- [ ] Arc<dyn>ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼ˆ20%ä»¥ä¸Šï¼‰
- [ ] ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®ãƒ¢ãƒƒã‚¯å¯èƒ½æ€§
- [ ] æœ¬ç•ªç’°å¢ƒã§ã®æœ€é©ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### Phase 5: ç›£è¦–ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆWeek 6ï¼‰

**ã‚¿ã‚¹ã‚¯**:
1. `PerformanceMonitor` å®Ÿè£…
2. `QueryCache` å®Ÿè£…
3. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ

**æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ**:
- [ ] P50/P95/P99ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¿½è·¡
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡70%ä»¥ä¸Š
- [ ] ã‚¨ãƒ©ãƒ¼ç‡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### Phase 6: çµ±åˆãƒ†ã‚¹ãƒˆã¨æœ€é©åŒ–ï¼ˆWeek 7-8ï¼‰

**ã‚¿ã‚¹ã‚¯**:
1. E2Eãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Œæˆ
2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿæ–½
3. è² è·ãƒ†ã‚¹ãƒˆã¨ãƒœãƒˆãƒ«ãƒãƒƒã‚¯è§£æ
4. æœ€çµ‚èª¿æ•´ã¨æœ€é©åŒ–

**æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆ**:
- [ ] å…¨æ©Ÿèƒ½ã®E2Eãƒ†ã‚¹ãƒˆãƒ‘ã‚¹
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™é”æˆ
- [ ] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãªã—

## ğŸ“Š æˆåŠŸæŒ‡æ¨™ï¼ˆv3å›ºæœ‰ï¼‰

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | v2ç›®æ¨™ | v3ç›®æ¨™ | æ¸¬å®šæ–¹æ³• |
|------------|--------|--------|----------|
| **æ¤œç´¢ãƒ¬ã‚¹ãƒãƒ³ã‚¹** | <300ms | <200ms | P95ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· |
| **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡** | ãªã— | >70% | ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° |
| **ã‚¨ãƒ©ãƒ¼å›å¾©ç‡** | ãªã— | >80% | ãƒªãƒˆãƒ©ã‚¤æˆåŠŸç‡ |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡** | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | -20% | ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚° |
| **ã‚³ãƒ¼ãƒ‰è¡Œæ•°/ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«** | <150è¡Œ | <200è¡Œ | tokei |
| **ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸** | 80% | 90% | cargo tarpaulin |
| **ãƒ“ãƒ«ãƒ‰æ™‚é–“** | 60ç§’ | <45ç§’ | CI/CD |
| **æ–°æ©Ÿèƒ½é–‹ç™ºæ™‚é–“** | 3æ—¥ | 2æ—¥ | JIRA |

## ğŸš€ ãƒªã‚¹ã‚¯ç®¡ç†

### æŠ€è¡“çš„ãƒªã‚¹ã‚¯

| ãƒªã‚¹ã‚¯ | å½±éŸ¿ | ç¢ºç‡ | å¯¾ç­– |
|--------|------|------|------|
| FTS5ãƒ­ã‚¸ãƒƒã‚¯ç ´æ | è‡´å‘½çš„ | ä½ | å®Œå…¨ãªãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã€æ®µéšçš„ç§»è¡Œ |
| ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ– | é«˜ | ä¸­ | ç¶™ç¶šçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚° |
| ç§»è¡Œä¸­ã®ãƒ‡ãƒ¼ã‚¿æå¤± | è‡´å‘½çš„ | ä½ | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç”» |
| ãƒãƒ¼ãƒ å­¦ç¿’æ›²ç·š | ä¸­ | é«˜ | è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ãƒšã‚¢ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° |

### ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç”»

```yaml
rollback_triggers:
  - performance_degradation: "> 20%"
  - error_rate_increase: "> 5%"
  - data_corruption: "any"
  - team_velocity_drop: "> 50%"

rollback_procedure:
  1. feature_flag_disable: "v3_architecture"
  2. git_revert: "v3 branch"
  3. database_restore: "from backup"
  4. monitoring_alert: "team + stakeholders"
```

## ğŸ“ v2ã‹ã‚‰v3ã¸ã®ä¸»è¦æ”¹å–„ç‚¹

### æ–°è¦è¿½åŠ è¦ç´ 
- âœ… **FtsQueryBuilder**: æ—¥æœ¬èªå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã®ä¿è­·ã¨æœ€é©åŒ–
- âœ… **åˆ†å‰²Operations**: å˜ä¸€è²¬ä»»åŸå‰‡ã«åŸºã¥ã3ã¤ã®å°‚é–€Operations
- âœ… **éšå±¤çš„ã‚¨ãƒ©ãƒ¼**: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»æ“ä½œãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»ã‚·ã‚¹ãƒ†ãƒ ã®æ˜ç¢ºãªåˆ†é›¢
- âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹DI**: å…·è±¡å‹ã¨trait objectsã®æˆ¦ç•¥çš„ä½¿ã„åˆ†ã‘
- âœ… **ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ **: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
- âœ… **ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥**: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªçµæœã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

### æ”¹å–„ã•ã‚ŒãŸè¦ç´ 
- âœ… **æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: 200msä»¥ä¸‹ã®P95ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
- âœ… **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: å›å¾©å¯èƒ½æ€§åˆ¤å®šã¨ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
- âœ… **ãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£**: 90%ä»¥ä¸Šã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™
- âœ… **ä¿å®ˆæ€§**: 200è¡Œä»¥ä¸‹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¶é™

### ç¶­æŒã•ã‚ŒãŸè¦ç´ 
- âœ… **4å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: v2ã®ç°¡ç´ åŒ–å“²å­¦ã‚’ç¶™æ‰¿
- âœ… **ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«**: ç´”ç²‹ãªãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«å®Ÿè£…
- âœ… **Repositoryãƒ‘ã‚¿ãƒ¼ãƒ³**: ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹æŠ½è±¡åŒ–
- âœ… **MCPã‚µãƒ¼ãƒãƒ¼çµ±åˆ**: æ—¢å­˜æ©Ÿèƒ½ã®å®Œå…¨ã‚µãƒãƒ¼ãƒˆ

---

**æ–‡æ›¸æ”¹è¨‚å±¥æ­´**

| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ—¥ä»˜ | å¤‰æ›´å†…å®¹ | ä½œæˆè€… |
|------------|------|----------|--------|
| 3.0.0 | 2025-08-17 | ãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡æ‘˜äº‹é …ã‚’å®Œå…¨åæ˜ ã—ãŸæœ€çµ‚è¨­è¨ˆ | Architecture Team |
| 2.0.0 | 2025-08-17 | ã‚µãƒ¼ãƒ“ã‚¹å±¤å‰Šé™¤ã€Businesså±¤å°å…¥ | Architecture Team |
| 1.0.0 | 2025-08-17 | åˆç‰ˆï¼ˆ6å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ | Architecture Team |

**æ‰¿èª**

- [ ] æŠ€è¡“ãƒªãƒ¼ãƒ‰
- [ ] ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
- [ ] é–‹ç™ºãƒãƒ¼ãƒ 
- [ ] QAãƒãƒ¼ãƒ 